<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>HAL Answering Service — Demo</title>
<style>
  *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

  body {
    background: #0a0a0a;
    color: #e0e0e0;
    font-family: 'Courier New', Courier, monospace;
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    align-items: center;
  }

  .container {
    max-width: 640px;
    width: 100%;
    padding: 2rem 1.5rem;
  }

  h1 {
    text-align: center;
    font-size: 1.4rem;
    font-weight: normal;
    letter-spacing: 0.1em;
    margin-bottom: 0.3rem;
    color: #ff3030;
  }

  .subtitle {
    text-align: center;
    font-size: 0.85rem;
    color: #666;
    margin-bottom: 2rem;
  }

  /* HAL eye */
  .eye-container {
    display: flex;
    justify-content: center;
    margin-bottom: 1.5rem;
  }

  .eye {
    width: 80px;
    height: 80px;
    border-radius: 50%;
    background: radial-gradient(circle, #ff0000 0%, #cc0000 40%, #440000 70%, #1a0000 100%);
    box-shadow: 0 0 30px rgba(255, 0, 0, 0.3);
    transition: box-shadow 0.3s;
  }

  .eye.listening {
    box-shadow: 0 0 40px rgba(255, 0, 0, 0.5);
  }

  .eye.speaking {
    box-shadow: 0 0 60px rgba(255, 0, 0, 0.8);
    animation: pulse 1.2s ease-in-out infinite;
  }

  .eye.thinking {
    animation: think 0.8s ease-in-out infinite;
  }

  .eye.off {
    background: radial-gradient(circle, #333 0%, #222 40%, #111 70%, #0a0a0a 100%);
    box-shadow: none;
  }

  @keyframes pulse {
    0%, 100% { box-shadow: 0 0 40px rgba(255, 0, 0, 0.6); }
    50% { box-shadow: 0 0 80px rgba(255, 0, 0, 1); }
  }

  @keyframes think {
    0%, 100% { box-shadow: 0 0 30px rgba(255, 0, 0, 0.3); }
    50% { box-shadow: 0 0 50px rgba(255, 200, 0, 0.5); }
  }

  .status {
    text-align: center;
    font-size: 0.85rem;
    color: #888;
    margin-bottom: 1.5rem;
    min-height: 1.2em;
  }

  /* Controls */
  .controls {
    display: flex;
    justify-content: center;
    gap: 1rem;
    margin-bottom: 1.5rem;
  }

  button {
    font-family: inherit;
    font-size: 0.9rem;
    padding: 0.6rem 1.8rem;
    border: 1px solid #333;
    border-radius: 4px;
    cursor: pointer;
    transition: all 0.2s;
    background: #1a1a1a;
    color: #e0e0e0;
  }

  button:hover:not(:disabled) {
    border-color: #ff3030;
    color: #ff3030;
  }

  button:disabled {
    opacity: 0.3;
    cursor: not-allowed;
  }

  #btn-start {
    border-color: #ff3030;
    color: #ff3030;
  }

  #btn-end {
    border-color: #666;
  }

  /* Transcript */
  .transcript-label {
    font-size: 0.75rem;
    color: #555;
    text-transform: uppercase;
    letter-spacing: 0.15em;
    margin-bottom: 0.5rem;
  }

  .transcript {
    background: #111;
    border: 1px solid #222;
    border-radius: 4px;
    padding: 1rem;
    min-height: 250px;
    max-height: 400px;
    overflow-y: auto;
    margin-bottom: 1.5rem;
  }

  .transcript-entry {
    margin-bottom: 0.8rem;
    line-height: 1.5;
  }

  .transcript-entry:last-child { margin-bottom: 0; }

  .transcript-entry .role {
    font-weight: bold;
    font-size: 0.8rem;
  }

  .transcript-entry .role.agent { color: #ff3030; }
  .transcript-entry .role.caller { color: #5090ff; }

  .transcript-entry .text {
    color: #ccc;
    font-size: 0.85rem;
    margin-top: 0.1rem;
  }

  /* Audio level */
  .level-container {
    display: flex;
    align-items: center;
    gap: 0.5rem;
    margin-bottom: 1rem;
  }

  .level-label {
    font-size: 0.7rem;
    color: #555;
    min-width: 3rem;
  }

  .level-bar-bg {
    flex: 1;
    height: 4px;
    background: #222;
    border-radius: 2px;
    overflow: hidden;
  }

  .level-bar {
    height: 100%;
    background: #ff3030;
    width: 0%;
    transition: width 0.05s;
    border-radius: 2px;
  }

  /* Notice */
  .notice {
    text-align: center;
    font-size: 0.75rem;
    color: #555;
    margin-top: 1rem;
    line-height: 1.6;
  }

  .notice strong { color: #888; }
</style>
</head>
<body>
<div class="container">
  <h1>HAL ANSWERING SERVICE</h1>
  <p class="subtitle">Demo Mode</p>

  <div class="eye-container">
    <div class="eye off" id="eye"></div>
  </div>

  <p class="status" id="status">Click Start to begin</p>

  <div class="controls">
    <button id="btn-start" onclick="startCall()">Start Demo Call</button>
    <button id="btn-end" onclick="endCall()" disabled>End Call</button>
  </div>

  <div class="level-container" id="level-section" style="visibility: hidden;">
    <span class="level-label">Mic</span>
    <div class="level-bar-bg"><div class="level-bar" id="level-bar"></div></div>
  </div>

  <p class="transcript-label">Live Transcript</p>
  <div class="transcript" id="transcript"></div>

  <p class="notice">
    <strong>Tip:</strong> Use headphones for best results (avoids echo).<br>
    Requires a local LLM server running (e.g. LM Studio on port 1234).<br>
    <strong>LAN access:</strong> Mic requires HTTPS on non-localhost origins. In Chrome:
    <em>chrome://flags &rarr; Insecure origins treated as secure</em> &rarr; add this page's URL.
  </p>
</div>

<script>
// --- State ---
let ws = null;
let audioCtx = null;
let micStream = null;
let scriptNode = null;
let micSource = null;
let isCallActive = false;

// Playback queue
let playbackTime = 0;
let activeSources = [];
let isPlaying = false;

// --- Mu-law codec (ITU-T G.711) ---
const MULAW_BIAS = 0x84;
const MULAW_CLIP = 32635;
const MULAW_EXP_TABLE = [
  0,132,396,924,1980,4092,8316,16764
];

function linearToMulaw(sample) {
  // Clamp to int16 range
  sample = Math.max(-32768, Math.min(32767, Math.round(sample)));
  const sign = (sample < 0) ? 0x80 : 0;
  if (sample < 0) sample = -sample;
  sample = Math.min(sample, MULAW_CLIP);
  sample += MULAW_BIAS;

  let exponent = 7;
  for (let expMask = 0x4000; exponent > 0; exponent--, expMask >>= 1) {
    if (sample >= expMask) break;
  }
  const mantissa = (sample >> (exponent + 3)) & 0x0F;
  return ~(sign | (exponent << 4) | mantissa) & 0xFF;
}

function mulawToLinear(mulaw) {
  mulaw = ~mulaw & 0xFF;
  const sign = mulaw & 0x80;
  const exponent = (mulaw >> 4) & 0x07;
  const mantissa = mulaw & 0x0F;
  let sample = MULAW_EXP_TABLE[exponent] + (mantissa << (exponent + 3));
  if (sign) sample = -sample;
  return sample;
}

// --- Resampling ---
function downsample(float32Buf, fromRate, toRate) {
  const ratio = fromRate / toRate;
  const outLen = Math.floor(float32Buf.length / ratio);
  const out = new Float32Array(outLen);
  for (let i = 0; i < outLen; i++) {
    const srcIdx = i * ratio;
    const floor = Math.floor(srcIdx);
    const ceil = Math.min(floor + 1, float32Buf.length - 1);
    const frac = srcIdx - floor;
    out[i] = float32Buf[floor] * (1 - frac) + float32Buf[ceil] * frac;
  }
  return out;
}

function upsample(int16Samples, fromRate, toRate) {
  const ratio = toRate / fromRate;
  const outLen = Math.round(int16Samples.length * ratio);
  const out = new Float32Array(outLen);
  for (let i = 0; i < outLen; i++) {
    const srcIdx = i / ratio;
    const floor = Math.floor(srcIdx);
    const ceil = Math.min(floor + 1, int16Samples.length - 1);
    const frac = srcIdx - floor;
    const sample = int16Samples[floor] * (1 - frac) + int16Samples[ceil] * frac;
    out[i] = sample / 32768; // normalize to [-1, 1]
  }
  return out;
}

// --- Mic capture ---
let micBuffer = new Float32Array(0);
const TARGET_RATE = 8000;
const FRAME_SIZE = 160; // 20ms at 8kHz

function onAudioProcess(e) {
  if (!isCallActive || !ws || ws.readyState !== WebSocket.OPEN) return;

  const input = e.inputBuffer.getChannelData(0);

  // Update level meter
  let sum = 0;
  for (let i = 0; i < input.length; i++) sum += input[i] * input[i];
  const rms = Math.sqrt(sum / input.length);
  const pct = Math.min(100, rms * 500);
  document.getElementById('level-bar').style.width = pct + '%';

  // Always send mic audio to the server — server-side barge-in detection
  // needs to hear the caller even while HAL is speaking. The server will
  // send a 'clear' event to flush playback on barge-in.

  // Downsample to 8kHz
  const downsampled = downsample(input, audioCtx.sampleRate, TARGET_RATE);

  // Append to buffer
  const newBuf = new Float32Array(micBuffer.length + downsampled.length);
  newBuf.set(micBuffer);
  newBuf.set(downsampled, micBuffer.length);
  micBuffer = newBuf;

  // Send complete 20ms frames
  while (micBuffer.length >= FRAME_SIZE) {
    const frame = micBuffer.slice(0, FRAME_SIZE);
    micBuffer = micBuffer.slice(FRAME_SIZE);

    // Encode to mu-law bytes
    const mulawBytes = new Uint8Array(FRAME_SIZE);
    for (let i = 0; i < FRAME_SIZE; i++) {
      mulawBytes[i] = linearToMulaw(frame[i] * 32768);
    }

    // Base64 encode
    let binary = '';
    for (let i = 0; i < mulawBytes.length; i++) {
      binary += String.fromCharCode(mulawBytes[i]);
    }
    const payload = btoa(binary);

    // Send
    ws.send(JSON.stringify({
      event: 'media',
      media: { payload: payload }
    }));
  }
}

// --- Audio playback ---
function queuePlayback(mulawBase64) {
  const binary = atob(mulawBase64);
  const mulawBytes = new Uint8Array(binary.length);
  for (let i = 0; i < binary.length; i++) {
    mulawBytes[i] = binary.charCodeAt(i);
  }

  // Decode mu-law to int16
  const int16Samples = new Int16Array(mulawBytes.length);
  for (let i = 0; i < mulawBytes.length; i++) {
    int16Samples[i] = mulawToLinear(mulawBytes[i]);
  }

  // Upsample 8kHz -> audioCtx.sampleRate
  const float32 = upsample(int16Samples, TARGET_RATE, audioCtx.sampleRate);

  const buffer = audioCtx.createBuffer(1, float32.length, audioCtx.sampleRate);
  buffer.getChannelData(0).set(float32);

  const source = audioCtx.createBufferSource();
  source.buffer = buffer;
  source.connect(audioCtx.destination);

  const now = audioCtx.currentTime;
  const startAt = Math.max(now + 0.02, playbackTime);
  source.start(startAt);
  playbackTime = startAt + buffer.duration;

  isPlaying = true;
  const entry = { source: source, endTime: playbackTime };
  activeSources.push(entry);

  source.onended = () => {
    const idx = activeSources.indexOf(entry);
    if (idx !== -1) activeSources.splice(idx, 1);
    if (activeSources.length === 0) {
      isPlaying = false;
    }
  };
}

function clearPlayback() {
  for (const s of activeSources) {
    try { s.source.stop(); } catch {}
  }
  activeSources = [];
  playbackTime = 0;
  isPlaying = false;
}

// --- Transcript ---
function appendTranscript(role, text) {
  const div = document.getElementById('transcript');
  const entry = document.createElement('div');
  entry.className = 'transcript-entry';

  const roleSpan = document.createElement('div');
  roleSpan.className = 'role ' + (role === 'agent' ? 'agent' : 'caller');
  roleSpan.textContent = role === 'agent' ? 'HAL' : 'You';

  const textSpan = document.createElement('div');
  textSpan.className = 'text';
  textSpan.textContent = text;

  entry.appendChild(roleSpan);
  entry.appendChild(textSpan);
  div.appendChild(entry);
  div.scrollTop = div.scrollHeight;
}

// --- UI state ---
function setStatus(text) {
  document.getElementById('status').textContent = text;
}

function setEye(state) {
  const eye = document.getElementById('eye');
  eye.className = 'eye ' + state;
}

// --- Call control ---
async function startCall() {
  document.getElementById('btn-start').disabled = true;
  document.getElementById('btn-end').disabled = false;
  document.getElementById('transcript').innerHTML = '';
  setStatus('Requesting microphone access...');

  try {
    micStream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true,
      }
    });
  } catch (err) {
    setStatus('Microphone access denied. Please allow mic access and try again.');
    document.getElementById('btn-start').disabled = false;
    document.getElementById('btn-end').disabled = true;
    return;
  }

  // Create audio context
  audioCtx = new (window.AudioContext || window.webkitAudioContext)();

  // Set up mic capture
  micSource = audioCtx.createMediaStreamSource(micStream);
  // Buffer size 4096 at 48kHz ~ 85ms, good balance of latency and stability
  scriptNode = audioCtx.createScriptProcessor(4096, 1, 1);
  scriptNode.onaudioprocess = onAudioProcess;
  micSource.connect(scriptNode);
  scriptNode.connect(audioCtx.destination); // Required for ScriptProcessor to fire

  micBuffer = new Float32Array(0);
  playbackTime = 0;
  activeSources = [];
  isPlaying = false;
  isCallActive = true;

  document.getElementById('level-section').style.visibility = 'visible';
  setStatus('Connecting...');

  // Open WebSocket
  const protocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
  ws = new WebSocket(protocol + '//' + location.host + '/demo-stream');

  ws.onopen = () => {
    setStatus('Connected — HAL is greeting you...');
    setEye('speaking');
  };

  ws.onmessage = (event) => {
    const data = JSON.parse(event.data);

    if (data.event === 'media') {
      setEye('speaking');
      queuePlayback(data.media.payload);
    } else if (data.event === 'clear') {
      clearPlayback();
    } else if (data.event === 'transcript') {
      appendTranscript(data.role, data.text);
      if (data.role === 'agent') {
        // After last audio chunk plays, switch to listening
        // (the eye state will update as audio finishes)
      }
    } else if (data.event === 'hangup') {
      setStatus('HAL ended the call.');
      setEye('off');
      cleanup();
    }

    // Update eye based on audio state
    if (isCallActive && !isPlaying && data.event !== 'hangup') {
      setEye('listening');
      setStatus('Listening...');
    }
  };

  ws.onclose = () => {
    if (isCallActive) {
      setStatus('Call ended.');
      setEye('off');
      cleanup();
    }
  };

  ws.onerror = () => {
    setStatus('Connection error. Is the server running?');
    setEye('off');
    cleanup();
  };
}

function endCall() {
  if (ws && ws.readyState === WebSocket.OPEN) {
    ws.send(JSON.stringify({ event: 'stop' }));
  }
  setStatus('Call ended.');
  setEye('off');
  cleanup();
}

function cleanup() {
  isCallActive = false;

  if (scriptNode) {
    scriptNode.disconnect();
    scriptNode = null;
  }
  if (micSource) {
    micSource.disconnect();
    micSource = null;
  }
  if (micStream) {
    micStream.getTracks().forEach(t => t.stop());
    micStream = null;
  }

  clearPlayback();

  if (ws) {
    try { ws.close(); } catch {}
    ws = null;
  }
  if (audioCtx) {
    try { audioCtx.close(); } catch {}
    audioCtx = null;
  }

  document.getElementById('btn-start').disabled = false;
  document.getElementById('btn-end').disabled = true;
  document.getElementById('level-section').style.visibility = 'hidden';
  document.getElementById('level-bar').style.width = '0%';
}

// Clean up on page unload
window.addEventListener('beforeunload', () => {
  if (isCallActive) endCall();
});
</script>
</body>
</html>
